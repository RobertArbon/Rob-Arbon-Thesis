\let\textcircled=\pgftextcircled
\chapter{Metastable state selection for hidden Markov models}
\label{chap:hmm}




\section{Introduction}
\begin{table}
    \centering
    \caption[Important symbols]{\textsc{Important symbols used throughout this chapter}.}
    \begin{tabularx}{0.9\textwidth}{ l >{\raggedright\arraybackslash}X } 
    \hline
    \textbf{Symbol}  &  \textbf{Definition} \\
    \hline\hline
    $g$ & Number of hidden states in a HMM. \\
    $n$ & Number of observed states in a HMM. \\
    $\mathbf{\tilde{T}}$ & $g\times g$ HMM transition matrix. \\
    $\mathbf{E}$ & $g \times n$ emission matrix. $E_{ij}$ is the probability of observing a state $j$ given an hidden state $i$. \\
    $\tilde{\bm{\pi}}$ & Stationary distribution of hidden states \\
    $\{s_{t}\}$ & Trajectory of observed states \\
    $\{h_{t}\}$ & Trajectory of hidden states \\
    $\mathbb{P}(\{s_t\}|M)$ & Integrated or marginal observed likelihood: the probability of observing $\{s_t\}$ given the model $M$. \\
    $\mathbb{P}(\{(s_t, h_t)\}|M)$ & Integrated or marginal complete-data likelihood: the probability of observing both $\{s_t\}$ and $\{h_t\}$ given the model $M$.  \\
    $\mathcal{L}\left(\tilde{\mathbf{T}}, \mathbf{E}| \{s_t\}\right)$ &  HMM likelihood. \\
    $\theta$ & The HMM parameters, $\tilde{\mathbf{T}}$ and $\mathbf{E}$\\
    $\hat{\theta}$ & Maximum likelihood estimates of $\theta$ \\
    $\mathbf{M}$ & Membership matrix. $M_{ij}$ is the probability that a given observed state $i$ is a member of hidden state $j$. \\
    $H(s_{t}; \mathbf{M})$ & The information entropy associated with observed state $s_{t}$. \\
    $EN(\mathbf{M})$ & Classification entropy - the sum of the $H(s_{t}; \mathbf{M})$ over a whole trajectory data set. \\
    \hline
    \end{tabularx}
    \label{tab:hmm_symbols}
\end{table}

Chapter \ref{chap:msm} demonstrated using response surface methods and Bayesian optimisation to arrive at an optimal MSM. Typically MSMs are created with \num{100}s of basis states, or microstates, which are geometrically similar so that they describe with a high degree of precision the eigenvectors of $\mathbf{T}$. These eigenvectors describe dynamic processes such as loop opening and closing (e.g., in triosephosphate isomerase \cite{LoopMotionTriosephosphate} described in chapter \ref{chap:intro}) or rotations about dihedral angles  (e.g., in alanine dipeptide, chapter \ref{chap:msm}). While the microstate basis can provide quantitative agreement with experimental lifetimes and rates \cite{bowmanNetworkModelsMolecular2010},  descriptions in terms of \num{100}s of states, which only differ by small changes in atomic configuration, is cumbersome and difficult to interpret.  It is common practice to instead group ``similar'' (this will be made precise below) microstates into a small number of meaningful and interpretable \emph{macrostates}.  To continue the loop opening example of triosephosphate isomerase, the authors of reference \cite{LoopMotionTriosephosphate} created an MSM with 100 microstates, each one of which differed slightly along 120 different interatomic distances.  Rather than stop at this description, they showed that these microstates could be grouped into just two or three macrostates which provided a more meaningful description in terms of the loop being open or closed. 

When grouping or \emph{coarse-graining} microstates into macrostates there are three questions that need to be answered: 

\begin{enumerate}
    \item How are the microstates mapped to the macrostates?  i.e., for each microstate which macrostate does it get assigned to?  
    \item Given a mapping, what are lifetimes of, and transition rates between, the macrostates? In other words, what is the transition matrix $\widetilde{\mathbf{T}}$ in this new basis?
    \item Model selection: How can competing models be compared and selected? This includes selecting among different coarse-graining methods and selecting the number of macrostates? 

\end{enumerate}
It may also be useful to ask what is the purpose of the performing the coarse-graining?  Is it to classify states crisply into disjoint macrostates? Or is it to produce the most accurate description the kinetics in a coarse-grained basis?  These two purposes require different model selection criteria and may affect the optimum coarse-graining scheme.

\subsection{Assigning microstates to macrostates}

% and coarse-graining has been studied since at least 1969 \cite{kuoLumpingAnalysisMonomolecular, weiLumpingAnalysisMonomolecular1969}.


There are two main approaches to coarse-graining and clustering in general, which have already been briefly discussed in section \ref{sec:intro_coarse} of the introduction to this thesis. First, geometric clustering can be used to assign snapshots from molecular dynamics (MD) trajectories to microstates based on their geometric similarity, for example the root mean square deviation from a reference structure. The second approach is kinetic clustering where clustering is performed by explicitly grouping frames into states based on their kinetic properties.  Kinetic properties of a particular atomic configuration are determined by its location on the free energy landscape. In order to transition from one region to another a barrier, which combines enthalpic (potential energy) and entropic terms, must be surmounted \cite{wales_2004}.  Thus kinetic clustering amounts to grouping molecular configuration which lie in the same minima on the free energy surface into the same state (defining clusters which lie near or on transition states is also important and will be described below). Discrete path sampling is a method of kinetically clustering atomic configurations \cite{walesEnergyLandscapesCalculating2006}. To do this the free energy surface is estimated  by first finding minima and saddle points (transition states) in the \emph{potential energy} surface and then adding an estimate of the entropic contribution. However, this does not scale to large systems because finding potential energy minima results in large energy fluctuations with systems with large numbers of degrees of freedom (for example with explicitly solvated systems) \cite{noeTransitionNetworksModeling2008}. For larger systems, the MSM approach is to approximate kinetic similarity with geometric similarity. The preprocessing steps of projecting onto relevant molecular features and time-lagged independent component analysis (described in chapter \ref{chap:theory}), is to create a set of variables which allow identification of geometric distance with the kinetic distance \cite{noeKineticDistanceKinetic2015}. So if the distance between frames as measured in these new variables is small, then they can be assumed to have similar kinetic properties.  

Coarse-graining microstates into macrostates is conceptually similar to clustering MD frames or atomic configurations into microstates, except that the time or distance scale has been enlarged because of the questions being asked of the data. Understanding loop motions, which occur nanosecond and microsecond timescale, does not require resolution of the rotameric states of individual methyl groups, which occur on the picosecond timescale \cite{henzler-wildmanDynamicPersonalitiesProteins2007}.


There have been a wide variety of kinetic clustering methods developed for coarse-graining microstates into macrostates. The majority of these methods create macrostates corresponding to the same free energy minima. This means that two microstates, $a_{i}$ and $a_{j}$, in the same macrostate, $A$, interconvert more rapidly than to microstates $b_{k}$ in a different macrostate, $B$.  This is possible when there is a difference in the timescales of the processes that cause transitions between $A$ and $B$ versus the transitions within $A$ (or $B, C, \ldots$), and the macrostates are said to exhibit metastable dynamics \cite{noeProjectedHiddenMarkov2013a}.  

The most straight-forward method of coarse-graining is when the slow processes can be easily identified with a protein feature.  In reference \cite{wapeesittipanAllostericEffectsCyclophilin2019} a 200 state MSM was constructed to model allosteric modulation in the enzyme cyclophilin A.  The slow process was identified with a change in the $\chi_{1}$ angle of the Phe113 residue.  Coarse-graining could then be done `by hand' by assigning microstates into either of two macrostates based on whether $\chi_{1} = \pm\SI{60}{\degree}$.  When this is not possible due to the number of relevant degrees of freedom, algorithmic methods are necessary. The first method for explicitly coarse-graining the microstates of an MSM was Perron cluster cluster analysis (PCCA) \cite{deuflhardIdentificationAlmostInvariant2000a} and its subsequent `robust' alternative PCCA+ \cite{deuflhardRobustPerronCluster2005b} (which improved the method under low-data conditions).  Each eigenvector of the transition matrix $\mathbf{T}$ represents a dynamic process (e.g., loop opening) and the associated eigenvalue is related to its timescale.  The relative sign of microstates in this eigenvector denotes how the process evolves over time: microstates with a negative sign transition to states with positive sign and vice versa. PCCA uses this sign structure to coarse-grain states: microstates with the same sign get grouped into the same macrostate. Some recent examples include using PCCA+ to coarse-grain: the 100 microstates of loop 6 into `open' and `shut' macrostates in TIM \cite{LoopMotionTriosephosphate}; 237 microstates of the protease trypsin into seven macrostates each of which exhibited different binding affinities  to the inhibitor benzamidine \cite{plattnerProteinConformationalPlasticity2015}; 500 microstates of DNA quadruplexes into five metastable states in order to test the accuracy of different molecular mechanics force-fields compared to X-ray crystallography experiments \cite{islamExploringDynamicsPropeller2017}.  PCCA+ is also used in the hierarchical Nystr{\"o}m exstension graph method (HNEG, \cite{yaoHierarchicalNystromMethods2013a}).  Instead of the whole microstate basis, the transition matrix $\mathbf{T}$ is approximated with a subset of only the most well sampled states (the  Nystr{\"o}m  method is a method for approximating matrices with an appropriate submatrix). PCCA+ is used to coarse-grain the submatrix and the remaining microstates are grouped based on their transition probabilities to each macrostate.  HNEG  has been used to understanding the binding interface of the calcium sensor calmodulin \cite{shuklaConformationalHeterogeneityCalmodulin2016}. The Bayesian agglomerative cluster engine (BACE) \cite{bowmanImprovedCoarsegrainingMarkov2012a} uses Bayesian hypothesis testing to test whether a given microstate belongs in a given macrostate. BACE has been applied to modelling the loop dynamics of MDM2 (mouse double minute 2 homologue - a cancer drug target), coarse-graining a 2000 state MSM into 150 macrostates.  HEG and BACE are similar because they first assign well-sampled microstates, resulting in coarse-grainings which are more robust when including poorly sampled microstates.  The most probable path (MPP,\cite{jainIdentifyingMetastableStates2012a})  assigns microstates to the same macrostate if they occur on the sequence of microstates. This sequence is constructed by starting by starting with a microstate $i$ and the next state has the highest transition probability from $i$ (i.e., $\argmax_{j} T_{i,j}$). MPP has been used assign 12000 microstates of the folding of the villin headpiece protein (HP35) into five macrostates representing one unfolded, two intermediate and two folded states \cite{jainHierarchicalFoldingFree2014}.  The renormalisation group is a technique for making links between phenomena at different scales e.g., the link between microscopic atomic interactions and macroscopic phase transitions \cite{wilsonRenormalizationGroupCritical1983}. This technique has been applied to MSMs  \cite{orioliDimensionalReductionMarkov2016c} to derive a coarse-graining method which was used by the authors to reduce a 100 microstate description of the bovine  pancreatic  trypsin  inhibitor (BPTI) to three metastable folded states.  A conceptually different approach was taken with minimum variance cluster analysis (MVCA \cite{husicMinimumVarianceClustering2018}). Row $i$ of the transition matrix $T_{i,j}$ defines a probability distribution over all other microstates $j$. Two microstates $i$ and $k$ are similar if they have similar distributions $T_{i,j}$ and $T_{i,k}$. MVCA hierarchically clusters microstates based on a measure of the similarity of the two distributions. The authors used this to compare the number of metastable states of the fast folding protein CLN025 (chignolin) with two different molecular mechanics force-fields. They also extended this approach to cluster not just rows of a single transition matrix but also whole transition matrices of different force-fields and water models of the same system, thus highlighting the similarities between the different combinations.  

Projected Markov models include observer operator models (OOMs, \cite{wuProjectedMetastableMarkov2015}) and hidden Markov models (HMMs, \cite{noeProjectedHiddenMarkov2013a}). These are dynamical models which directly incorporate a microstate-macrostate structure into their definition.  PMMs assume Markovian dynamics in an unobserved state space and then specify a projection onto observable variables - OOMs and HMMs are different approximations to this process.  HMMs have been described in chapter \ref{chap:theory} but to summarise: HMMs specify a Markov process in hidden states (macrostates), while in each hidden state the system `emits' an observed microstate.  Each macrostate emits with a different set of probabilities to each microstate. This emission distribution defines the coarse-graining.  HMMs are accurate representations of PMMs assuming the unobserved dynamics are metastable and the emission distributions do not overlap.  OOMs on the other hand do not require non-overlapping emission distributions and are therefore considered the more general model \cite{wuProjectedMetastableMarkov2015}. HMMs have proved the more popular model and have been used to model protein-protein association dynamics \cite{plattnerCompleteProteinProtein2017}, ligand binding \cite{mondalAtomicResolutionMechanism2018a, yangMappingPathwayDynamics2018, ahalawatMappingSubstrateRecognition2018, olaposiMembraneBoundTranscriptionFactor2019, hansonWhatMakesKinase2019}, enzyme-substrate dynamics \cite{panConformationalHeterogeneityMichaelis2016, wangDynamicalBehaviorVLactamases2019, curado-carballadaHiddenConformationsAspergillus2019}, nucleic acid folding dynamics \cite{FastFoldingPathwaysThrombinBinding2018, remingtonFluorescenceQuenching2aminopurinelabeled2019}, ion channels \cite{furiniIontriggeredSelectivityBacterial2018}, allosteric effects \cite{xiaoNaBindingModes2019} and to aid in enzyme design \cite{juarez-jimenezDynamicDesignManipulation2020}. This is likely due to their attractive properties for understanding conformational dynamics.  First, there is a clear one-to-one relationship between the elements of the model and the intuition about the conformational dynamics of biomolecules: the rapidly inter-converting configurations correspond to the observed states of the HMM, while the metastable states correspond to the hidden states of the HMM \cite{noeProjectedHiddenMarkov2013a}. Second, unlike MSMs the dynamics of the observed states (or microstates in the language of MSMs) are not required to be Markovian in order to recover the relaxation timescales. Third, they have been shown to be robust to poor microstate definitions \cite{noeProjectedHiddenMarkov2013a}. 

The previous techniques all focused on creating definitions of macrostates which were metastable, i.e., correspond to minima in the free energy surface. However, transition states are crucial to describing the rates of conformational transitions and increasing the number of microstates around the barrier separating free energy minima increases the accuracy of Markov models \cite{prinzMarkovModelsMolecular2011}.  In reference \cite{martiniVariationalIdentificationMarkovian2017} the authors coarse-grain microstates to find both metastable \emph{and} transition-state macrostates. The central idea is to select macrostates which maximize the slowest implied timescale in the macrostate model. This variational bound on the slowest timescale in the coarse-grained picture was later proved \cite{kellsMeanFirstPassage2019}.  The authors went on to apply this to a wide variety of systems: quantum-mechanics/molecular mechanics multiscale simulations of hydrogen abstraction in lipoxygenase, the model helix forming  alanine pentapeptide, and two different helix dimers. 


\subsection{Coarse-grained description of kinetics}

In order to make the link between the coarse-grained description and observable dynamical properties of the system and new coarse-grained transition matrix is required.   In general, defining a new macrostate transition matrix by simply merging microstates will result in a non-Markovian description which fails to correctly propagate the element of $\mathbf{p}$ in the master equation (equations \ref{eqn:masterequation} and \ref{eqn:discretemasterequation}) \cite{kubeCoarseGrainingMethod2007b, noeProjectedHiddenMarkov2013a}. The authors of reference \cite{kubeCoarseGrainingMethod2007b} attempted to define a coarse-grained transition matrix by minimizing the error between the predicted populations of states in macrostate and microstate basis. As their numerical example illustrated however, their method could result in unrealistic negative transition probabilities.  A more successful approach was proposed by Hummer and Szabo  \cite{hummerOptimalDimensionalityReduction2015a}. Their method enforced consistency between the microstate and macrostate descriptions of the relaxation times between macrostates. This result was used in the method of reference \cite{martiniVariationalIdentificationMarkovian2017} to identify transition-state macrostates described previously. The Hummer-Szabo method was used in reference \cite{jasHelixCoilTransition2018} to calculate the macrostate transition matrix derived from 199 microstate MSM coarse-grained  using PCCA+. Later work also showed \cite{kellsCorrelationFunctionsMean2020} their method to be equivalent preserving mean first passage times (the average time taken to transition between states) between the microstate and macrostate basis. 

For some coarse-graining techniques the construction of a consistent macrostate transition matrix is more straightforward. The renormalization group technique \cite{orioliDimensionalReductionMarkov2016c} defines simultaneously the micro-macrostate mapping and the macrostate rate matrix and so no further work is necessary. For projected Markov models (HMMs and OOMs) the transition matrix is estimated directly from the data. For HMMs this is done by maximizing the likelihood of the model parameters (the transition matrix elements and the emission distribution parameters) or through Bayesian estimation. In both types of estimation the likelihood function makes the link between the observed trajectories of microstates and the coarse-grained transition matrix and the assignment of microstates to macrostates.  Each observed microstate in a trajectory can be thought of as arising from two processes: emission and transition. At time $t$ the system is in a given macrostate $h_{t}$; this macrostate `emits' a microstate $s_{t}$ with a given probability $E_{h_{t}, s_{t}}$.  The macrostate itself arose because of a transition from an earlier macrostate $h_{t-1}$ with a probability of $\widetilde{T}_{h_{t-1}, h_{t}}$. The likelihood function relates the observed microstates to elements of the matrices  $\mathbf{E}$ and $\widetilde{\mathbf{T}}$. The optimal macrostate basis is defined by finding $\mathbf{E}$ and $\widetilde{\mathbf{T}}$ which maximize the likelihood. This is covered in detail in chapter \ref{chap:theory} and later in section \ref{sec:hmm_methods}.


\subsection{Model selection}

The number of macrostates, $g$, must be stipulated when coarse-graining a MSM but choosing an appropriate value of $g$ is complicated by two factors. First, the nature of complex systems is that there is a hierarchy of timescales \cite{frauenfelderEnergyLandscapesMotions1991, henzler-wildmanDynamicPersonalitiesProteins2007} which define multiple different metastable and transition-state coarse-graining. The number of macrostates must therefore be set in relation to a timescale. Even after setting this timescale, none of the methods so far give a definitive answer as to how many macrostates should be specified, however some give more information to guide the user than others. For example, the Bayesian agglomerative clustering engine \cite{bowmanImprovedCoarsegrainingMarkov2012a} hierarchically assigns microstates, initially to a large number of  macrostates, which are in turn assigned into larger macrostates until only two macrostates remain. Thus the user can see how states agglomerate and choose the number of macrostates according to their specific analysis objective. The `distance' between the macrostates (i.e., the number of iterations before two distinct states are merged) is measured by the Bayesian weight of evidence for merging two states (this is the Bayes factor, discussed below).  By requiring stronger evidence for merging two states a more fine grained picture with more macrostates is produced.  In the transition-state coarse-graining method of reference \cite{martiniVariationalIdentificationMarkovian2017} the algorithm can by stopped after identification of a single transition-state macrostate or can keep going finding more transition-state macrostates which again produces a more fine-grained picture.  A more general method for determining the number of metastable macrostates is to inspect the eigenvalue spectrum of the MSM in the microstate basis.  Gaps in the eigenvalues or the implied timescales \cite{noeProjectedHiddenMarkov2013a} denote regions where there is a separation in timescales. A large gap between the $g$ and the $g+1$'th timescale supports coarse-graining into $g$ metastable macrostates. 

The second complicating factor is the finite amount of data which often leads to gaps in the implied timescale which are statistically indistinguishable from one another \cite{bowmanQuantitativeComparisonAlternative2013}, making it difficult to determine $g$.  In practice this means that noise in the data could be interpreted as a separate metastable state, a phenomena known as over-fitting \cite[chapter 6]{friedman2001elements}. This observation drove the the development of PCCA+ over the original PCCA method \cite{deuflhardRobustPerronCluster2005b} and many of the other methods described previously \cite{bowmanQuantitativeComparisonAlternative2013}.  

Deciding on the number of macrostates a given set of simulation data supports is an example of the problem of model selection \cite[chapter 6]{friedman2001elements}\cite{claeskens_hjort_2008}. Chapter \ref{chap:msm} was an example of model selection where the choices being decided upon related to the creation of optimum microstates.  This focus of this chapter is on the number of metastable macrostates in a coarse-grained Markov model. One approach to determining the number of macrostates is through Bayes factors \cite{kassBayesFactors1995}. The Bayes factor, BF, of two models, $M_{1}$ and $M_{2}$ relates the posterior odds of two models, given the data, $D$, to the prior odds of the models \cite{kassBayesFactors1995}:
\begin{align}
\text{Posterior odds} & = \text{Bayes Factor} \times \text{Prior odds} \\
\frac{ \mathbb{P}(M_1|D) }{ \mathbb{P}(M_2|D) } & = \frac{ \mathbb{P}(D|M_1) }{ \mathbb{P}(D|M_2) } \times \frac{ \mathbb{P}(M_1) }{ \mathbb{P}(M_2) }\\
& = \frac{\int \mathbb{P}\left( D | \theta_{1} \right)\mathbb{P}(\theta_{1}|M_{1}) \mathrm{d}\theta}{\int \mathbb{P}\left( D | \theta_{2} \right)\mathbb{P}(\theta_{2}|M_{2}) \mathrm{d}\theta} \times \frac{\mathbb{P}(M_1)}{\mathbb{P}(M_2)}\label{eqn:bf_final}
\end{align}
The integral in the definition of the BF runs over all the potential values of the model parameters, $\theta$, weighted by their prior probability $P(\theta)$. If the prior odds is one, i.e., there is no prior reason to favour one model over another, then the BF is equal to the posterior odds of the two models. If $\textrm{BF} > 1$ then model $1$ is favoured and vice versa. The Bayes factor measures the relative evidence of two models provided by the data \cite{kassBayesFactors1995}. In the case of coarse-graining Markov models for conformational dynamics, the data are the discrete microstate trajectories $D = \{s_1, s_2, ...\}= \{s_t\}$, and the model is, for example a HMM, represented by its parameters $\theta = (\tilde{\mathbf{T}}, \mathbf{E})$ \cite{bacalladoBayesianComparisonMarkov2009a}. Practical use of the Bayes factor amounts to calculating the integrated likelihood  for each model $M_i$ and selecting the model with the largest value. Using this method, quantitative comparisons of several of the lumping schemes previously cited  (excluding HMMs) were  compared for a number of benchmark systems \cite{bowmanQuantitativeComparisonAlternative2013}. Bayes factors are attractive as they naturally penalise overly complex models, i.e. models with high-dimensional parameter vectors $\theta$. The reason is that while the likelihood $\mathbb{P}(D|\theta)$ may increase with the dimension $\theta$ due to the increased flexibility of the model, the prior probability of any particular $\theta$ decreases as it occupies a smaller fraction of this higher dimensional parameter space \cite{kassBayesFactors1995,mackay2003information}. However, the main drawback of Bayes factors is the computational effort required to estimate integrals of the type in equation \ref{eqn:bf_final}, which restricts the number of models that can be compared. 


\subsection{Hidden Markov models}

The proceeding discussion has shown that there exist many different methods for coarse-graining microstates to macrostates. In order to describe the kinetics of the system in the macrostate basis a method for calculating the macrostate transition matrix is required, the method of Hummer and Szabo \cite{hummerOptimalDimensionalityReduction2015a} is one such method which can be applied to different coarse-graining scheme and maintains important properties from the microstate description. Recent work showed that the optimum coarse-grained description can then be derived by maximizing the slowest timescale in macrostate transition matrix \cite{kellsCorrelationFunctionsMean2020, kellsMeanFirstPassage2019}. For other methods such the the renormalization group \cite{orioliDimensionalReductionMarkov2016c} and hidden Markov models \cite{noeProjectedHiddenMarkov2013a} the macrostate transition matrix arises directly for application of the method. Choosing the number of macrostates is a problem common to all coarse-graining methods and must take into account the timescale of the problem being investigated and the finite amount of data used to estimate models. Bayes factors are a solution to this problem but require a separate, computationally intensive calculation to estimate. 

The remaining discussion and the focus of the chapter will be on the use of hidden Markov models for coarse-graining Markov state models.  In particular the problem of hidden Markov model selection will be discussed and investigated. The choice of HMMs is motivated because of their established popularity for coarse-graining MSMs and, because of their long-standing use in other fields, there are a wide range of techniques available for model selection which are simpler that the Bayes factor approach. These other techniques and the link to the Bayes factor will constitute the remainder of this introductory discussion. 


\subsection{Classification versus density estimation}

\begin{figure}
    \centering
    \caption[Classification and density estimation with mixture models]{\textsc{Classification and density estimation with mixture models}. Panels (a) and (b) show the classification picture for a two and three component Gaussian mixture model estimated on the same data. The generating (true) densities are shown as black dashed lines, and the generated data shown underneath as coloured discs. The estimated densities are shown as coloured lines. The data have been coloured according to their maximum a posteriori assignment to each estimated component, the transparency of the colour is proportional to the classification entropy - the more uncertain the assignment the more transparent. The label shows the log classification likelihood ($LL_{\mathrm{c}}$) and entropy ($EN$). Panels (c) and (d) show the same two models but the densities have been added so as to reproduce the total density of the data. The label shows the log likelihood ($LL$). The data generating distributions are $\mathcal{N}(1, (\sfrac{1}{2})^{2})$, $\mathcal{N}(5, (\sfrac{2}{3})^{2})$, $\mathcal{N}(6.6, (\sfrac{2}{3})^{2})$, mixed in proportions $\bm{\pi}=(0.34, 0.34, 0.32)$.}
    \includegraphics[width=0.8\textwidth]{chapters/hmm_selection/figures/class_like_explainer.png}
    \label{fig:hmm_class_lik_explainer}
\end{figure}

Hidden Markov models are a type of finite mixture model \cite{mclachlanFiniteMixtureModels2000}. Finite mixture models are used for two purposes (a) modelling the density of observations and (b) classifying observations into meaningful groups \cite{mclachlan1988mixture} and can be related to the purposes of coarse-graining MSMs. A coarse-graining is designed to classify observations or microstates into meaningful groups, namely metastable macrostates.  Modelling the `density of observations' in this case means that the macrostate picture should be consistent with equilibrium distribution of microstates and their propagation through time. There is a natural tension between these two purposes.  On the one hand more macrostates can model the dynamic processes more accurately but at the expense of losing meaning and interpretability of the macrostates.  

Model selection techniques exist which take into account the diverging purposes of classification and density estimation. To understand them a  simplified example using a Gaussian mixture model (GMM, \cite{reynolds2009gaussian}) will be used. The reason for using this model as an example is that GMMs share essential features with a HMM, while dispensing with the complicating factor of dynamics, and are easy to visualise.  

A GMM groups observations as though they arose from draws from a Gaussian distribution. This is demonstrated in figure \ref{fig:hmm_class_lik_explainer} which shows $N = \num{87}$ random draws (coloured discs) from three normal distributions (black dashed lines). In panel (a) a two component Gaussian mixture model (GMM) has been estimated. To do this, the data $\{s_{1}, \ldots, s_{\mathrm{N}}\}$ were modelled as arising from the weighted sum of two normal distributions: $s \sim \pi_{1}\mathcal{N}\left(\mu_{1}, \sigma_{1}^{2}\right) +  \pi_{2}\mathcal{N}\left(\mu_{2}, \sigma_{2}^{2}\right)$. The values of the parameters $\theta = (\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \pi_{1}, \pi_{2})$ were chosen to maximise the log likelihood $\log{\mathcal{L}(\theta | \{s_{i}\})} = \mathbb{P}(\{s_{i}\}|\theta)$.  The coloured lines show the estimated normal distributions and the observations have been classified and coloured as arising from either one of the normal distributions. To classify the observations, the posterior probability of an  observation, $s_{i}$, arising from component $j$ (the distribution with parameters $\mu_{j}, \sigma_{j}$), was calculated: $M_{ij}=\mathbb{P}(s_{i} \in \text{component }j |s_{i})$ for each value of $j$. The observations were assigned to the component with the highest value of $M_{ij}$. This is known as the maximum a posteriori (MAP) assignment. In panel (c) the same model is shown but the total probability density (the sum of the probability density functions) is shown along with the log likelihood ($LL$). The same thing is repeated for a three component model in panels (b) and (d). So panels (a) and (b) reflect on GMMs as a method of classification, while panels (c) and (d) reflect on GMMs as a method of density estimation. 

How can the two models be evaluated?  For the purposes of density estimation, the estimated density of the three component model (panel (d) blue line) captures the bimodal distribution of the cluster of observations $x \in [4, 8]$ better than the two component model. This is to be expected as the data was generated from a three component mixture and the log likelihood reflects this: $LL=\num{-164}$ vs. $LL=\num{-160}$ for the two and three component models respectively. From a classification perspective the situation is reversed. For both models, the cluster of data around $x\simeq 1$ is unambiguously classified as belonging to a single component. For the two component model this is also true of the observations $x  \in [4, 8]$. However, for the three component model, the  distributions of the second and third components overlap in the small region around $x\simeq 5.8$. This means the posterior probabilities for belonging to either component, $M_{i, 2},\ M_{i, 3}$,  for the observations in this region will be similar. Therefore, it is not possible to unambiguously assign observations to either component $j=2$ or $j=3$. This is reflected in the log \emph{classification} likelihood, $LL_{c}$ which for the three component model is smaller than the two component model: $LL_{c}=\num{-170}$ vs. $LL_{c} = \num{-165}$. The log classification likelihood and the log likelihood are related by $LL = LL_{c} - EN$, where $EN$ is the classification entropy \cite{hathaway1986another}.  The entropy of an observation, $s_i$, is the information entropy  $H_i = \sum_{j}^{g}M_{ij}\log{M_{ij}}$  and measures the uncertainty with which the observation can be assigned to a given component \cite{mackay2003information}. The classification entropy is the sum of the individual entropies over the observations \cite{mclachlanFiniteMixtureModels2000}. So although the three component model has a higher \emph{likelihood} than the two component model, it has a lower \emph{classification likelihood} because it cannot assign all the observations with certainty to each component. 


The relationship between the Gaussian mixture model described above and a hidden Markov model is straightforward \cite{mclachlanFiniteMixtureModels2000}. The observations in a continuous state space of the GMM $s_{i} \in \mathbb{R}$ map to the discrete microstate trajectories of a HMM, $s_{t} \in \mathbb{Z}$; the GMM components are the hidden states of the HMM $h_{t}$; the distribution parameters $\mu_{i},\ \sigma_{i}$ are the rows of the emission matrix, $E_{i, \cdot}$; and the mixing proportions of the GMM are are stationary distribution $\bm{\pi}$ of the HMM. Considering HMMs as a coarse-graining procedure means they are aligned the second purpose of mixture models: \emph{classifying observations into meaningful groups}, where the `meaningful groups' are the system's metastable states. The classification likelihood is also known as the complete-data likelihood because the classification procedure adds in a new variable, the identity of the component associated with each observation \cite{mclachlanFiniteMixtureModels2000}. The complete-data likelihood takes both the observation \emph{and} the component variable into account \cite{mclachlan1988mixture}. To emphasise the difference between the likelihood and the complete-data likelihood, the former will be referred to as the observed likelihood.  

As shown above, a low value of the classification entropy indicate that the emission distributions do not overlap - one of the assumptions under which HMMs are valid representations of PMMs. However, although the relative values of $LL$ and $LL_{c}$ for the two models in the above example demonstrate the difference between the classification and density estimation paradigms for mixture models, using them to assess the number of components, using for example a likelihood ratio test \cite{wasserman2013all} is difficult. For a thorough discussion on the reasons for this see section 6.4 of reference \cite{mclachlanFiniteMixtureModels2000} but briefly it arises from the fact that one can always estimate a model where the stationary distribution of one hidden states is zero thus making a smaller model (with fewer hidden states) potentially indistinguishable from the larger model. The Bayes factor approach is to integrate out all potential values of $\theta$ from the likelihood as described above. This is also possible with classification likelihood \cite{latoucheBayesianMethodsGraph2010} although to the best knowledge of the author of this thesis, this has not been done for reversible hidden Markov models. The two likelihood approaches for HMMs may be concisely compared as follows. The integrated observed likelihood (Bayes factor approach) measures the evidence for the HMM provided by the observed microstate trajectories, while the integrated complete-data likelihood measures the evidence for the model  given by the observed microstates and the given hidden states \cite{biernackiAssessingMixtureModel2000a, celeuxSelectingHiddenMarkov2008}. 

\subsection{Model selection criteria}

Although the integrated observed and complete-data likelihoods are Bayesian quantities which generally require numerical approximation \cite{gelmanBayesianDataAnalysis2014}, analytic approximations exist which extend their use to models estimated using maximum likelihood \cite{kassBayesFactors1995, mclachlanFiniteMixtureModels2000}. The most widely used approximation to the integrated observed likelihood is the Schwarz criterion \cite{schwarzEstimatingDimensionModel1978a}, which up to an arbitrary factor is the Bayesian information criterion, BIC. The BIC was derived in the context of linear models and the approximations used are not valid in the finite mixture context, however there are other theoretical and practical reasons in favour of their use \cite{fraley1998many}. The analogue of the BIC for the integrated classification likelihood is the integrated complete-data likelihood criterion, ICL \cite{biernackiAssessingMixtureModel2000a}.  The derivation of the ICL makes use of the same approximations as the BIC and so shares its drawbacks, however, in simulation experiments (for both HMMs and mixture models in general) it has performed well \cite{mclachlanFiniteMixtureModels2000,celeuxSelectingHiddenMarkov2008, biernackiAssessingMixtureModel2000a}.

Another type of approach to selecting the number of hidden states in maximum likelihood HMMs is via minimization of the Kullback-Liebler (KL) divergence \cite{kullbackInformationSufficiency1951}. The KL divergence  measures the difference between the modelled distribution and the true distribution. Two criteria which minimize this value are the Akaike-information criterion, AIC \cite{akaikeInformationTheoryExtension1998}, and the cross-validated log-likelihood, CVLL \cite{celeuxSelectingHiddenMarkov2008}.  


As will be seen in this chapter, the benefits of the information criteria, BIC, ICL, and AIC, are that they require  very little extra calculation once a maximum likelihood HMM has been estimated. This is important as the search space of different models and number of hidden states may be large, rendering a more detailed Bayesian analysis for every potential model infeasible. However these methods have drawbacks both practical, mathematical and inferential. One potentially unrealistic assumption is that model selection using the AIC and BIC (and by analogy, the ICL) requires that the model representing the true data generating process must be in the model under consideration \cite{ripley_1996}. As HMMs are by design an approximation to the true dynamics, this may be an unreasonable assumption. The reasons for this differ between the AIC and BIC however - for the Bayesian argument for the BIC see chapter 6 of reference \cite{bernardo2007bayesian}. In addition, the BIC and ICL criteria use approximations that are only valid under certain technical regularity conditions \cite{mclachlanFiniteMixtureModels2000}. These are the same difficulties which arise for  model selection using $LL$ and $LL_{c}$.  The benefit of the CVLL  is that it is conceptually simple but practically  one must estimate many HMMs to evaluate the number of hidden \cite{celeuxSelectingHiddenMarkov2008}. Other criteria exist for selecting the number of hidden states, for example the Penalised Marginal Likelihood criterion, PML \cite{gassiatLikelihoodRatioInequalities2002} for MLE HMMs which circumvents some of the issues alluded to for the BIC, as well as a range of Bayesian model selection techniques \cite{gelmanBayesianDataAnalysis2014,bernardo2007bayesian}, however these are not considered here. 


Previous work \cite{mcgibbonStatisticalModelSelection2014a} evaluated the use of the AIC, BIC and CVLL for selecting the number of microstates in Markov state models. However, choosing MSM parameters has since been superseded by the variational approach to learning Markov process (see chapter \ref{chap:msm}). This aim of this chapter is to builds on this work and investigates the use of the BIC, ICL, AIC, and CVLL to identify the number of hidden states in a HMM used for coarse-graining a MSM. It is similar to the investigation of these criteria in reference \cite{celeuxSelectingHiddenMarkov2008} but uses data simulated from the four well Prinz potential. This is an interesting extension of typical simulation benchmarks because the dynamics of the Prinz potential is (a) already approximately Markovian in the observed states \cite{prinzMarkovModelsMolecular2011} and (b) the dynamics does not derive from an existing HMM (unlike most simulation studies which use data derived from an HMM process). The results of this chapter will be applied to the case of coarse-graining MSMs of AADH in chapter \ref{chap:aadh}.  The structure of this chapter is as follows: in section \ref{sec:hmm_methods} the Prinz potential and the model selection criteria will be explained; section \ref{sec:hmm_results} discusses the results and section \ref{sec:hmm_conclusions} discusses the conclusions and limitations.


\section{Methods} \label{sec:hmm_methods}
\subsection{Prinz potential}
\begin{figure}[p]
    \centering
    \caption[The Prinz potential]{\textsc{The Prinz potential} \cite{prinzMarkovModelsMolecular2011}. Panel (a) shows the potential $V(x)$, in blue and the stationary distribution, $\pi(x)$ in orange. Panel (b) shows the exact ratio of successive eigenvalues resolvable with a MSM with $\tau=5$. Panel (c) shows the exact ratio of successive timescales. Panel (d) shows the estimated implied timescales, $\hat{t}_{i}$, as coloured dashed lines with \SI{95}{\percent} credible intervals estimated using trajectories sampled from the potential using a Bayesian HMM with $1000$ draws from the posterior. The exact values, $t_{i}$, are shown as similarly coloured solid lines. The values of $\tau = 5, 8, 15, 65, 130$ used in the model selection experiments are shown as vertical black lines.}
    \includegraphics[width=0.8\textwidth]{chapters/hmm_selection/figures/prinz_pot.png}
    \label{fig:prinz_pot}
\end{figure}

The Prinz potential \cite{prinzMarkovModelsMolecular2011} is shown in figure \ref{fig:prinz_pot}.  Panel (a) shows the four well potential, $V(x)$, in blue and the stationary distribution, $\pi(x)$, showing the four metastable states, in orange. Panel (b) show the  ratio of successive eigenvalues resolvable by a  MSM with $\tau=5$. The large gap between the fourth and fifth eigenvalues implies four metastable states. Panel (c) shows the exact ratio of implied timescales. The implied timescales show a large gap between the second and third implied timescale. From this potential \num{100} independent trajectories were sampled, initialized from random draws from the stationary distribution, discretised into \num{410} microstates and used as data for estimating the HMMs in this work. Each trajectory was twice the length of the longest timescale. The number of microstates was chosen as the square root of the number of observations, inline with the heuristic in reference \cite{husicWardClusteringImproves2017a}. See appendix \ref{app:hmm} for full details of the Prinz potential and simulation details. Panel (d) shows the mean implied timescales and \SI{95}{\percent} credible intervals as a function of the Markov lag time estimated with a Bayesian HMM. The exact timescales are also shown as solid lines. The estimated HMMs capture the exact times to within statistical uncertainty for all values of $\tau$ except for $t_{4}$ for $\tau < 8$. The number of hidden states used in these HMMs was determined by the lag time and the exact timescales of the full Prinz transfer operator (see table \ref{tab:prinz_its_exact}). For example for $\tau = 130$ only $t_2 = 844$ is resolvable so a two hidden state HMM was used. The time and rate units used throughout this chapter are in terms of the time-step used to integrate the equations of motion, $\Delta t = 0.001$, and the distance units are arbitrary, see appendix \ref{app:hmm}.

\subsection{Model selection criteria}

In the following sections, the likelihood, $\mathcal{L}$, of the HMM parameters will feature heavily and so is repeated here for convenience \cite{noeProjectedHiddenMarkov2013a}: 

\begin{equation}\label{eqn:obs_lik_full}
\begin{split}
    \mathcal{L}\left(\tilde{\mathbf{T}}, \mathbf{E}| \{s_t\}\right) & = \mathbb{P}\left(\{s_t\} | \tilde{\mathbf{T}}, \mathbf{E}\right) \\
    & = \sum_{\substack{\{h_t\} \in \\ \text{all paths}}} \tilde{\pi}_{h_{0}}E_{h_{0},s_{0}}\prod_{t=1}^{t_{max}}\tilde{T}_{h_{t-1}, h_t}E_{h_t, s_t}    
\end{split}
\end{equation}
This is the likelihood of the parameters of the transition matrix and emission matrix ($\tilde{\mathbf{T}}, \mathbf{E}$ respectively) given the trajectory of observed states $\{s_t\}$. The multiplicand represents the probability of observing Markovian transition between hidden states (the $\tilde{T}_{h_{t-1}, h_{t}}$ term) and then  observing the observed states (the $E_{h_t, s_t}$ term) \cite{noeMarkovModelsMolecular2019b, rabinerTutorialHiddenMarkov1989}. The summand represents summing the probability over all possible combinations (paths) of hidden states, while $\tilde{\pi}_{h_{0}}E_{ h_{0}, s_{0}}$ is the probability of the initial hidden state/observed state pair \cite{noeMarkovModelsMolecular2019b, rabinerTutorialHiddenMarkov1989}. This summation is infeasible for even small numbers of hidden states and trajectory lengths (e.g. for $2$ hidden states and a trajectory of $100$ frames, there are approximately $10^{30}$ potential paths). The Baum-Welch algorithm \cite{rabinerTutorialHiddenMarkov1989} was developed to maximize the likelihood through expectation maximisation. An outline of the Baum-Welch algorithm can be found in algorithm \ref{alg:baum_welch}, while the full details for maximum likelihood HMMs can be found in reference \cite{noeProjectedHiddenMarkov2013a}. The maximum likelihood estimates of the parameters will be denoted $\hat{\theta}$, so the maximum of the observed likelihood function will be denoted $\mathcal{L}\left(\hat{\theta}|\{s_t\}\right)$. 

Selecting the number of hidden states using CVLL and the AIC both minimize the \emph{Kullback-Leibler} divergence, $D_{\mathrm{KL}}(p||q)$ \cite{mclachlanFiniteMixtureModels2000}. This is a measure of the difference between a given probability distribution, $p(s)$ and a reference distribution, $q(s)$ \cite{mackay2003information, kullbackInformationSufficiency1951}: 

\begin{equation}\label{eqn:kl_div}
\begin{split}
    D_{\mathrm{KL}}\left(p\mid | q\right) & = \int q(s) \log{\left(\frac{ q(s) }{p(s)}  \right)} \mathrm{d}s \\ 
    & = \int q(s) \log{\left(q(s)\right)}\mathrm{d}s - \int q(s)\log{\left(p(s)\right)} \mathrm{d}s
\end{split}
\end{equation}
When the two distributions are the same $D_{\mathrm{KL}} = 0$. The first term is the average information of $q(s)$, also known as the information entropy \cite{mackay2003information}. This is continuous analogue of the information entropy discussed in the introduction, albeit for a different distribution. The second term is average information of $p(s)$ but averaged over reference distribution \cite{mackay2003information}. In the context of model selection, $p(s)$, is taken to be the modelled distribution $\mathbb{P}(\{s_t\}|\hat{\theta})$ and $q(s)$ is the unknown true distribution \cite{mclachlanFiniteMixtureModels2000}. As only the latter term is dependent on the modelling choices and  $D_{\mathrm{KL}} \ge 0$ (Jensen's inequality \cite{mackay2003information}) maximizing this term will lead to the model closest to the true distribution \cite{mclachlanFiniteMixtureModels2000}.  

The AIC approximates the second term in equation \ref{eqn:kl_div} and is defined as \cite{akaikeInformationTheoryExtension1998}:
\begin{equation}\label{eqn:aic}
    \operatorname{AIC} = -2\log{\left(\mathcal{L}\left(\hat{\theta}|\{s_t\}\right)\right)} + 2d
\end{equation}
where $d$ is the number of degrees of freedom of the model. For a reversible Markov transition matrix with $g$ states this is: $d = \sfrac{1}{2}g(g-1) + (g-1)$ \cite{trendelkamp-schroerEstimationUncertaintyReversible2015b}. The emission distribution adds $g(n-1)$, as for every hidden state $g$ there are $n$ probabilities which must sum to $1$ \cite{noeProjectedHiddenMarkov2013a, rabinerTutorialHiddenMarkov1989} giving $n-1$ degrees of freedom per hidden state. So the total degrees of freedom for a reversible HMM is:
\begin{equation}\label{eqn:hmm_dof}
    d = \sfrac{1}{2}g(g-1) + (g-1) + g(n-1). 
\end{equation}
The derivation of the AIC starts by approximating the true distribution, $q(s)$, with the distribution over $s$ estimated from the data, which gives rise to the $\log{\mathcal{L}\left(\hat{\theta}|\{s_t\} \right)}$ term \cite{mclachlanFiniteMixtureModels2000}.  This will naturally over-fit to the data and the $d$ term attempts to account for this. $d$ is only equal to the degrees of freedom of the model under the assumption that the true model is under consideration in the model selection procedure \cite{ripley_1996}.  The factor of $-2$ is there to make an equivalence with Mallows $C_p$ \cite{friedman2001elements} although this does not affect the final results. The selected model is the one which has the smallest AIC \cite{friedman2001elements}. 

Instead of approximating $q(s)$ with $\mathcal{L}\left(\hat{\theta}|\{s_t\}\right)$ and making a bias correction, cross-validation can be used to approximate the second term of equation \ref{eqn:kl_div} \cite{celeuxSelectingHiddenMarkov2008}. In this work, the CVLL was calculated in the following way (note method was derived by the author of this thesis as the procedure in \cite{celeuxSelectingHiddenMarkov2008} deals with a different type of CV procedure): 
\begin{enumerate}
    \item The observed trajectories were split into $N = 10$ training $\{s_t\}^{i}$ and test $\{s_t\}^{-i}$, $i = 1, ..., N$ sets using 50:50 shuffle-split (algorithm \ref{alg:shuffle_split}). 
    \item For each $i$, an HMM was estimated using the training data $\{s_t\}^{i}$.\label{step:hmm_est} 
    \item Calculate the log-likelihood of the training parameters using the test data,  $\log{\left(\mathcal{L}\left(\hat{\theta}^{i}\middle|\{s_t\}^{-i}\right)\right)}$, with the forward part of the Baum-Welch algorithm (algorithm \ref{alg:baum_welch}). This was achieved by taking the parameters calculated in step \ref{step:hmm_est}, $\hat{\theta}^{i}$, then using the \texttt{forward} function from the Python package BHMM (version 0.6.3) using these parameters and the test data $\{s_{t}\}^{-i}$ as arguments. \label{step:cvll}
    \item The CVLL is the average over the splits: 
    \begin{equation}
        \operatorname{CVLL} = \frac{1}{N}\mathlarger{\sum}_{i}^{N}\log{\left(\mathcal{L}\left(\hat{\theta}^{i} \middle | \{s\}^{-i}\right)\right)}
    \end{equation}
\end{enumerate}
There are two potential points of failure in this procedure. First, the HMM may fail to converge on a given fold. Second, the `forward' part of the Baum-Welch algorithm may fail to give a finite estimate for the log-likelihood. If either of these failures occurred, the CVLL value for that number of hidden states was considered invalid. 

The BIC comes from consideration of the integrated observed likelihood, $\mathbb{P}\left(\{s_t\}\right)$ used in the definition of the Bayes factor \cite{kassBayesFactors1995}: 
\begin{equation}\label{eqn:obs_lik_int}
       \mathbb{P}\left(\{s_t\}|M\right) = \int \mathbb{P}\left(\{s_t\}\middle|\theta \right)\mathbb{P}\left(\theta \middle | M\right) \mathrm{d}\theta,
\end{equation}
where $\mathbb{P}(\theta|M)$ is the prior distribution over the HMM parameters for a given model specification. The integrated likelihood selects the model with the greatest evidence for the observed states, i.e., the model with the highest posterior probability, given the observed states and taking into account the increased flexibility of more complex models \cite{mackay2003information,kassBayesFactors1995}. The BIC is an approximation to the logarithm of equation \ref{eqn:obs_lik_int} and is given by \cite{schwarzEstimatingDimensionModel1978a}:
\begin{equation}\label{eqn:bic}
    \operatorname{BIC} = -2\log{\left(\mathcal{L}\left(\hat{\theta}\middle| \{s_t\}\right)\right)} + d\log{\left(N_{\mathrm{obs}}\right)}
\end{equation}
where $d$ is the degrees of freedom and $N_{\mathrm{obs}}$ is the number of observations.  The difference in BIC between two models, $\mathrm{BIC}_{1}-\mathrm{BIC}_{2}$ is an approximation to the log of the Bayes factor, the selected model is then the one with the smallest BIC \cite{friedman2001elements}.  The derivation of the BIC proceeds by expanding the log of the integrand in equation \ref{eqn:obs_lik_int},  $\log{\left(\mathbb{P}\left(\{s_{t}\}\middle |\theta \right)\right)}$ in a Taylor series about $\hat{\theta}$ up to second order \cite{mclachlanFiniteMixtureModels2000, friedman2001elements}. The regularity conditions alluded to in the introduction amount to the ability to safely ignore the higher order terms in this expansion \cite{mclachlanFiniteMixtureModels2000}.

The derivation of the ICL follows an analogous path to the BIC but takes as its starting point the integrated complete-data likelihood \cite{biernackiAssessingMixtureModel2000a}: 
\begin{equation}\label{eqn:class_lik_int}
    \mathbb{P}\left(\{(s_t, h_t)\}\middle | M \right) = \int \mathbb{P}\left(\{(s_{t}, h_{t})\}\middle |\theta \right)\mathbb{P}\left(\theta\middle | M\right) \mathrm{d}\theta
\end{equation}
The integrated complete likelihood selects the model with the greatest evidence for the observed states \emph{and} the hidden states \cite{biernackiAssessingMixtureModel2000a}. As the hidden states are not observed they are taken to be MAP assigned values: $h_t = \argmax_{j} M_{s_{t}, j}$. The ICL is an approximation to $\log{\left(\mathbb{P}(\{(s_t, \hat{h}_t)\}\middle | M \right)}$ and is given by \cite{biernackiAssessingMixtureModel2000a}:
\begin{equation}\label{eqn:icl}
\begin{split}
        \operatorname{ICL} &= -2\log{\left(L\left(\hat{\theta}\middle|\{s_t\}\right)\right)} + d\log{\left(N_{\mathrm{obs}}\right)} +2\cdot EN\left(\mathbf{M}\right)     \\
        & = \operatorname{BIC} + 2\cdot EN\left(\mathbf{M}\right)
\end{split}
\end{equation}

The $EN$ term  is classification entropy given by \cite{biernackiAssessingMixtureModel2000a}:
\begin{equation}\label{eqn:class_entropy}
\begin{split}
     EN\left(\mathbf{M}\right) & = \sum_{t}^{N_{\mathrm{T}}}(-1)\sum_{j}^{g} M_{s_{t}, j}\log{\left(M_{s_{t}, j}\right)}  \\ 
     & =\sum_{t}^{N_{\mathrm{T}}} H\left(s_{t}; \mathbf{M}\right)
\end{split}
\end{equation}
Here $\mathbf{M}$ is the membership matrix $M_{ij}= \mathbb{P}(h=j|s=i)$ and $H$ is the information entropy $H\left(s_{t};\mathbf{M}\right) = -\sum_{j} M_{s_{t}, j}\log{\left(M_{s_t, j}\right)}$. This entropy quantifies the uncertainty with which the model assigns the given observed state to a hidden state \cite{mackay2003information}. For example in a two hidden state system, given an observed state which could belong in hidden state 1 with probability \SI{50}{\percent} or in hidden state 2 with probability \SI{50}{\percent}, then the entropy for that observation is:
\begin{equation}
\begin{split}
    H\left(s; \mathbf{M}\right) & =  -\sum_{j} M_{s_{t}, j}\log{\left(M_{s_t, j}\right)} \\
    & = -\sfrac{1}{2}\log{\left(\sfrac{1}{2}\right)} - \sfrac{1}{2}\log{\left(\sfrac{1}{2}\right)} \\
    & = \log{\left(2\right)}
\end{split}
\end{equation}
 
\subsection{Criteria calculation details}\label{sec:hmm_details}
There are a number of practical details in calculating the information criteria which need to be addressed. 

The number of observations, $N_{\mathrm{obs}}$, needed for the BIC and ICL, was calculated as the number of pairs of observations which go into the count matrix. Using the sliding window count method this is:
\begin{equation}\label{eqn:hmm_nobs}
    N_{\mathrm{obs}} = N_{\mathrm{traj}}\cdot\frac{(N_{\mathrm{T}} - \tau)}{\Delta t}
\end{equation}
where $N_{\mathrm{traj}}$ is the number of trajectories, $N_{\mathrm{T}}$ is the length of each trajectory, $\tau$ is the Markov lag time and  $\Delta t$ is the trajectory time-step. The total number of frames is $N_{\mathrm{frames}} = N_{\mathrm{traj}}\cdot N_{\mathrm{T}} /\Delta t$

The classification entropy was calculated using the hidden state probabilities calculated in the final iteration of the Baum-Welch (B-W) algorithm (algorithm \ref{alg:baum_welch}): 
\begin{enumerate}
    \item For each observed state in a trajectory, $s_t$, the conditional probability, $\gamma_{i}(t)=\mathbb{P}\left(h_{t}=i \mid s_t, \theta\right)$, was extracted from the final iteration of `update' part of the B-W algorithm. 
    \item The entropy was calculated for each frame of the trajectory,  $H(t)=-\sum_{i}\gamma_{i}(t)\log{\left(\gamma_{i}(t)\right)}$ and then summed over the $N_{\mathrm{T}}$ frames of a trajectory and then over the $N_{\mathrm{traj}}$ trajectories: $EN = \sum^{N_{\mathrm{traj}}} \sum_{t}^{N_{\mathrm{T}}} H(t)$.
    \item $N$ was scaled by a factor of $N_{\mathrm{obs}}/N_{\mathrm{frames}}$ to account for the fact that an observation is a pair of states $(s_{t}, s_{t+\tau})$.
\end{enumerate}
A second method was available, which in principle should give the same answer but which in practice diverged by up to a factor of three from the above method. The entropy was calculated using the membership matrix, itself calculated from the emission matrix, $\mathbf{E}$, and the stationary distributions of the hidden $\widetilde{\bm{\pi}}$ and observed $\bm{\pi}$ states: 
\begin{equation}\label{eqn:M_vs_E}
    M_{ji} = E_{ij}\frac{\widetilde{\pi}_{i}}{\pi_{j}}
\end{equation}
where $i$ labels the $g$ hidden states and $j$ labels the $n$ observed states. The entropy was calculated using $\mathbf{M}$ as: 
\begin{equation}\label{eqn:ent_v2}
    \mathrm{EN}(\mathbf{M}) = N_{\mathrm{obs}}\sum^{n}_{j}(-1)\pi_{j}\sum^{g}_{i} M_{ji}\log{\left(M_{ji}\right)}
\end{equation}
The reason for the difference was due to error accumulated in the values of  $\mathbf{M}$ from equation \ref{eqn:M_vs_E}. This was due to noise in the poorly sampled observed states, see section \ref{sec:app_membership_errors} and figure \ref{fig:membership_error}. However, in situations when the largest reversible connected set of hidden states is smaller than total number of hidden states, the values of $\gamma$ would need re-normalizing. In this case (in particular in chapter \ref{chap:aadh}) the second method will be more convenient. 

All HMM and MSM fitting was performed in Python 3.7 using the packages PyEMMA (version 2.5) \cite{schererPyEMMASoftwarePackage2015a}, NumPy (version 1.19) \cite{waltNumPyArrayStructure2011}, Pandas (version 0.23) \cite{mckinneyPandasFoundationalPython2011}, Matplotlib (version 3.3) \cite{hunterMatplotlib2DGraphics2007},  Seaborn (version 0.10) \cite{michaelwaskomMwaskomSeabornV02020} and the Jupyter Project (version 4.6) \cite{kluyverJupyterNotebooksPublishing2016}. The calculation of the cross-validated log-likelihood used the Python package Bayesian hidden Markov model toolkit (BHMM, version 0.6.3). All scripts to calculate the AIC, BIC and ICL were written by the author of this thesis. 


\subsection{Model selection}
The model selection criteria were used to select the optimum number of hidden states in a maximum likelihood HMM, using the discrete trajectories sampled from the Prinz potential. Five different values of the Markov lag time were used: $\tau=5,\ 8,\ 15,\ 65,\ 130$. These values were chosen because they resolve, respectively $7,\ 5,\ 3,\ 2,\ 1$ implied timescales in the full MSM state space and as the top three of these timescales are dominant (figure \ref{fig:prinz_pot} panel (b)), these values of $\tau$ resolve $4,\ 4,\ 4,\ 3,\ 2$ metastable states  respectively \cite{noeProjectedHiddenMarkov2013a}.

For each value of $\tau$ maximum likelihood HMMs were estimated with $g = 2 - 10$ hidden states. For each of the $45$ model specifications (different values of $\tau$ and $g$) the model selection criteria were calculated  and the number of hidden states selected by each was compared to the true value. 

\section{Results and discussion}\label{sec:hmm_results}
\begin{table}
    \centering
    \caption[Hidden state selection results]{\textsc{Hidden state selection results}. The selected number of hidden states, $\hat{g}$, by the CVLL, AIC, BIC and ICL for each value of $\tau$. The true values, $g^{\mathrm{true}}$ are also shown. The asterisk highlights where $\hat{g}=g^{\mathrm{true}}$. The number in parentheses shows $\hat{g}-g^{\mathrm{true}}$. }
    \begin{tabular}{llrrrr}
    \toprule
    $\tau$ & $g^{\mathrm{true}}$ & CVLL & AIC & BIC & ICL  \\
    \midrule
     $5$  & $4$ & $4^{*} (0)$  & $10 (6)$ & $10 (6)$ & $5 (1)$ \\
     $8$  & $4$ & $4^{*} (0)$ & $10 (6)$ & $8 (4)$  & $4^{*} (0)$  \\
     $15$ & $4$ & $4^{*} (0)$  & $9 (5)$ & $6 (2)$  & $4^{*} (0)$  \\
     $65 $& $3$ & $4 (1)$  & $5 (2)$  & $4 (1)$  & $3^{*} (0)$  \\
     $130$& $2$ & $4 (2)$  & $4 (2)$  & $3 (1)$  & $3 (1)$  \\
     \bottomrule
    \end{tabular}
    \label{tab:prinz_criteria_results}
\end{table}

\begin{figure}
    \centering
    \caption[Hidden state selection criteria]{\textsc{Hidden state selection criteria}. Rows (a) - (e) show the selection criteria for HMMs with $\tau=5, 8, 15, 65, 130$ respectively. The best performing number of hidden states is indicated by an arrow. Column (i) shows the CVLL. Column (ii) shows the AIC. The log-likelihood term is shown in blue and the degrees of freedom penalty ($2d$) is shown in orange. Column (iii) shows the BIC. The penalty term $d\cdot\log{N_{obs}}$ is shown in green.  Column (iv) shows ICL. The classification entropy penalty term $2\cdot EN$ is shown in red. Missing values indicate the failure of the HMM to converge. All values have been scaled so the minimum value in each panel is $1$.}
    \includegraphics[width=0.75\textwidth]{chapters/hmm_selection/figures/prinz_h_state_selection.png}
    \label{fig:prinz_criteria_results}
\end{figure}

The selected number of hidden states using each criterion are shown in table \ref{tab:prinz_criteria_results} where the asterisk denotes when a criteria selects the correct number of hidden states. The relative values of the selection criteria are shown in figure \ref{fig:prinz_criteria_results}. Each row, (a) - (e), corresponds to models estimated with a  different value of the Markov lag time $\tau=5,\ 8,\ 15,\ 65,\ 130$. Each column, (i) - (iv), corresponds to the different model selection criteria, CVLL, AIC, BIC, and ICL. The minimum value of each criteria for each model is highlighted with an arrow indicating the selected number of hidden states, $\hat{g}$. The values are scaled so the value at the selected number of states the value of the criterion is equal to $1$.  The coloured bars show the contributions of the different parts of each score. The blue bars shows the log-likelihood terms of equations \ref{eqn:aic}, \ref{eqn:bic} and \ref{eqn:icl} i.e.  $-2\times \log{\left(\mathcal{L}\left(\hat{\theta}\middle |\{s_t\}\right)\right)}$. In the case of CVLL, the blue bars are the  cross-validated equivalent. The various penalty terms are shown in orange ($2d$, the AIC penalty), green ($d\log{N}$, the BIC penalty) and red ($2\cdot EN$, the classification entropy). 

The ICL performs best by correctly identifying the number of hidden states for $\tau=8,\ 15,\ 65$. It fails at $\tau=5$ where the hidden state dynamics are not quite Markovian (figure \ref{fig:prinz_pot} panel (d)). Although the selected value of $5$ is close to the true value of $4$, the ICL does not discriminate between $g=4 - 7$: their ICL values vary by less than \SI{1}{\percent}, as shown in figure \ref{fig:prinz_criteria_results} panel (a)(iv). The ICL also fails at $\tau=130$, however the minimum value of the ICL is similar to the value for the true number of hidden states, $g = 2$, and is significantly different to the values for $g \ge 4$,  as shown in panel (e)(iv). In this case the ICL does distinguish between two sets of values of $g$, which include the true value on the one-hand, and the remaining values on the other. This behaviour is in contrast to the results in reference \cite{celeuxSelectingHiddenMarkov2008} in which the ICL correctly identified the number of hidden states for well separated emission distributions, and with large numbers of observations for less well separated distributions. However, for smaller numbers of observations and less well separated clusters, the ICL \emph{under-estimated} the number of hidden states. The ICL also under-estimated the number of clusters in the finite mixture context when the clusters are not well separated \cite{biernackiAssessingMixtureModel2000a}. 

The CVLL correctly selects four states for $\tau = 5,\ 8,\ 15$, however this was due failure of the cross-validation to produce a finite answer on some of the cross-validation folds. For example, for $\tau=5$, at least one cross-validation fold did not estimate the out-of-sample log-likelihood for $g\ge 4$. The remaining values are shown in figure \ref{fig:prinz_criteria_results} column (i). This causes problems with interpretation as is it is not clear whether failure is due to the  inefficiency of the cross-validation procedure or whether the given number of hidden states really has zero out-of-sample likelihood. The former is more likely given that models estimated on \SI{100}{\percent} of the data do converge and give interpretable answers. Given the lack of convergence for many of the values of $g$ comparison with the literature is difficult. The results in reference \cite{celeuxSelectingHiddenMarkov2008} show that the CVLL behaves similarly to the ICL but with less discrimination between values of $g$ i.e., in repeated experiments the distribution of selected values of $g$ was wider for the CVLL. In contrast, the results for $\tau=130$ in figure \ref{fig:prinz_criteria_results} panel (e)(i) show the CVLL over-estimates the number of hidden states.  Given the poor performance of the CVLL in this experiment it will not be discussed further here. 

The AIC overestimates for every value of $\tau$ and as $\tau$ increases the values of the AIC discriminate less between each value of $g$: for $\tau = 130$ the AIC for all $g$ are within \SI{2}{\percent} of each other. This is in contrast to the results in reference \cite{celeuxSelectingHiddenMarkov2008} which the AIC selected the correct or underestimated the value of $g$. However, in simulation studies for finite mixtures (without the Markovian dynamics of the hidden states) the AIC frequently over-estimated the number components \cite{celeuxEntropyCriterionAssessing1996, soromenho1994comparing}. The BIC also overestimates the number of hidden states for all values of $\tau$ but only by $1$ for $\tau=65$ and $130$. This is in contrast to the results in reference  \cite{celeuxSelectingHiddenMarkov2008} for which the BIC behaved similarly to the ICL and either estimated correctly or under-estimated the number of hidden states.  In addition, for finite mixtures the BIC has also been shown to under-estimate the number of components \cite{biernackiAssessingMixtureModel2000a}.

Although the AIC, BIC and ICL are derived from different starting points, they all take the form of the log-likelihood plus a penalty term, $b$:
\begin{equation}
    -2\log{\left(\mathcal{L}\left(\hat{\theta} \middle|\{s_t\}\right)\right)} + b
\end{equation}
The $b$ term in each case penalises the complexity of each model. The behaviour of these criteria can be understood in terms of the interplay between the likelihood and penalty terms. The log-likelihood, the blue bars in columns (ii)-(iv) of figure \ref{fig:prinz_criteria_results}, monotonically increases with $g$ for all values of $\tau$ (this is shown as a decrease due to the $-2$ in the definition of the criteria). This is most pronounced for small values of $\tau$ (compare panel (a)(ii) to (e)(ii)), and demonstrates both over-fitting and the HMMs ability to capture the fast relaxation processes of the Prinz dynamics. Consider the $g=10$ model selected by the AIC for $\tau=8$, figure \ref{fig:prinz_tau8_g10} (the results are similar for $\tau=5$). This figure shows the sign structure of the exact relaxation processes (panels (a) - (c)) and those estimated from the HMM (panels (d) - (f)). The HMM captures the sign structure of the second and fifth relaxation process,  panels (d) and (e), as they have associated timescales larger than $\tau$, ($t_{2}=844.4, t_{5} = 11.9 > \tau=8$) and are thus resolvable. The 10th estimated relaxation process (panel (f)) only approximate the true relaxation process (panel (c)) as the estimated timescale $\hat{t}_{10} = 4.0$ is less than the lag time, $\tau=8$. For larger values of $\tau$ and $\tau= 130$ in particular (figure \ref{fig:prinz_criteria_results} panel (e)(ii)), the likelihood remains constant. This is because many of the estimated HMM relaxation processes over-fit to noisy fluctuations in the data. 

\begin{figure}
    \centering
    \caption[Comparison of estimated and true Prinz potential dynamics]{\textsc{Comparison of estimated and true Prinz potential dynamics}. The true Prinz potential are compared with a HMM with $\tau=8$ and $g=10$ hidden states. Panels (a) - (c) shows the sign structure of the 2nd, 5th and 10th right eigenvector of the Prinz potential ($\mathrm{sgn}[\Psi(x)]$, shaded area). The Prinz potential ($V(x)$, blue solid line) is shown for reference. The exact timescales are labelled on the top right as $t_{2/5/10}$.  Panels (d) - (f) show the sign structure of the hidden state relaxation processes, projected onto the observed states. The eigenvectors projected onto the observed state basis, $q_{2/5/10}(x) = \sum_{i} E_{i, x} \cdot \tilde{\Psi}_{2/5/10}(i)$ , are shown as dotted lines, the summands are shown as coloured lines. The shaded areas are $\mathrm{sgn}[q_{2/5/10}(x)]$. The estimated timescales are labelled on the top right as $\hat{t}_{2/5/10}$. }
    \includegraphics[width=0.8\textwidth]{chapters/hmm_selection/figures/hmm_tau_8_g_10.png}
    \label{fig:prinz_tau8_g10}
\end{figure}

The AIC the penalty term, $b=2d$ (orange bars in figure \ref{fig:prinz_criteria_results}, column (ii)), is there to correct the approximation of the KL divergence by log-likelihood. It increases proportional to $g^{2}$ (equation \ref{eqn:hmm_dof}) but only affects the selected $g$ for $\tau=15,\ 65,\ 130$ (figure \ref{fig:prinz_criteria_results} panels (c)(ii), (d)(ii) and (e)(ii)). The origin of the BIC penalty term, $b=d\log{N_{obs}}$ (green bars, column (iii)) is to correct the approximation of the integrated likelihood by the maximum log-likelihood. The BIC over-estimates the number of hidden states albeit by a smaller number than the AIC, due to the penalty term rising faster with $g$ by a factor $\log{N_{\mathrm{obs}}}/2$. As pointed out in reference \cite{mcgibbonStatisticalModelSelection2014a} when using the sliding window method for calculating the count matrix the value of $N_{\mathrm{obs}}$  will be overestimated. However, as the dynamics is approximately Markovian for $\tau > 5$ the difference between the sliding window and sample count methods will be negligible. 

\begin{figure}
    \centering
    \caption[The classification entropy of HMMs]{\textsc{The classification entropy of HMMs}. Panels (a)-(c) show the emission distributions of HMMs with $\tau=8$ and $g = 2, 4, 10$ respectively. Each coloured line represents the emission distribution, $E_{i, x}$,  of the hidden states, $i$. Panels (d) - (f) show the information entropy for observed state at $x$, weighted by the stationary distribution over the observed states: $\pi(x)H(x)$. The label shows the average classification entropy per observation $EN_{\mathrm{ave}} = \sum_{x}\pi(x)H(x)$.}
    \includegraphics[width=0.8\textwidth]{chapters/hmm_selection/figures/prinz_entropy.png}
    \label{fig:prinz_ent}
\end{figure}

The ICL penalty term $b=d\log{N}+2\cdot EN$ corrects the approximation to the integrated complete-data likelihood by the log-likelihood. It is comprised of the BIC penalty term (green bars in figure \ref{fig:prinz_criteria_results}) and the entropy term (red bars). This is associated with increasing $g$ directly through the BIC penalty term, $\simeq g^{2}\log{N_{obs}}$, and indirectly due the overlap of emission distributions. This is demonstrated in figure \ref{fig:prinz_ent}. Panel (a) shows the emission distribution for a two state HMM. These two distributions only overlap around $x=0$. Panel (d) shows the information entropy at each value of $x$, weighted by the stationary distribution over the observed states, $\pi(x)$\footnote{the information entropy here the same calculation which determined the transparency of the observations in figure \ref{fig:hmm_class_lik_explainer} panel (b).}. The information entropy is zero almost everywhere as each observed state can be assigned unambiguously to a hidden state. The exception is around $x=0$ where the entropy reaches its highest possible value of $\log{2}$. However, the average classification entropy per observation, $\sum_{x}\pi(x)H(x)$ is low as the fraction of observations at $x=0$, $\pi(0)$, is negligible. As the number of hidden states increases, panels (b) and (c), the  entropy increases because the emission distributions overlap more, and the average entropy increases because they overlap in regions which are visited more often i.e. where $\pi(x)$ has significant density (panels (e) and (f)). As column (iv) of figure \ref{fig:prinz_criteria_results} shows, the entropy penalty is the source of the success of the ICL in selecting  the correct number of hidden states. 

Minimizing the entropy penalty alone is similar to maximizing the crispness/scaling condition in PCCA+ (equation 4.19 in reference \cite{deuflhardRobustPerronCluster2005b}) in that it maximizes the number of  observed states that are unambiguously assigned to one hidden state. However, the minimum entropy solution by itself (ignoring the other terms) will always favour two hidden states separated by the slowest relaxation process, which for small $\tau$ does not capture the potential other metastable states. The ICL balances the need for a `crisp' assignment with the need for hidden states needed to accurately  model the transition matrix. 

\section{Conclusions}\label{sec:hmm_conclusions}
Four model selection criteria have been compared for identifying the number of hidden states in HMMs of dynamics simulated from the four-well Prinz potential. The four criteria fall into two categories - those than aim to minimize the Kullback-Liebler divergence, the CVLL and the AIC, and the those that maximize a type of integrated likelihood, the BIC and ICL. The CVLL was of limited usefulness because it was unable to produce results for a significant proportion of the models tested and because of its relatively large computational requirement. The AIC and BIC both overestimated the number of hidden states although the BIC by fewer states than the AIC. These results do not match the results from previous studies on selecting the number of components in mixture models and in HMMs. The ICL, which maximizes the integrated complete-data likelihood performed best by correctly identifying three out of five hidden states and where it failed it only overestimated by one extra hidden state. The main limitations of this work is that it did produce a statistical estimate of the selected number of hidden states. In other studies \cite{biernackiAssessingMixtureModel2000a} the criteria are judged on an ensemble of models with similar characteristics and also on a range models with different characteristics.  

The data from the four state model used to test these criteria limits the conclusions that can be drawn. The dynamics used to generate the trajectories was Markovian by construction meaning observations were independent of one another.  This ensured that the underlying assumption of independent and identically distributed  (i.i.d.) observations, which is required of all  criteria tested here, was met. However, in molecular dynamics simulations more commonly use for biomolecular simulations, frames are correlated at short times which violates these assumptions. Separate testing with molecular dynamics simulations is required to see how this lack of independence affects these criteria. The sampling of the data was also unrealistic in other ways: first, the trajectories were sampled from equilibrium distribution; second, to total length of simulation data was 200 times the longest relaxation timescale. Neither of these conditions is met in typical simulations.  With less data the danger of over-fitting will increase as the likelihood function will increase more rapidly with the number of macrostates than the compensating complexity penalties of the various criteria (the number of degrees of freedom, the number of observations, and the classification entropy). 

A second limitation is the nature of the Prinz potential which is smooth, with none of the  hierarchical structure arising from the many degrees of freedom typical of biochemical systems. One potential remedy for this deficiency is to introduce some randomness to the potential to simulate a more rugged potential energy landscape. The effect of a more complex energy landscape would be to increase the number of potential energy minima and dynamical processes. Again,the likelihood function is likely to increase rapidly with the number of macrostates as the model seeks to explain these processes, raising the possibility of over fitting, even if these processes are more rapid than the dominant relaxation timescales. 

Potential avenues for testing the ICL further with model potentials would be to both increase the ``roughness'' of the four-well potential and to decrease the amount of data used to estimate the HMMs. This would allow a more realistic assessment of its applicability while still having a definitive number of metastable states, which is not always easy to ensure with real systems. 


However, under the idealised conditions of the model the ICL is a promising candidate for HMM state selection. The integrated complete-data likelihood is a natural criterion for the purpose of coarse-graining  MSMs of conformational dynamics. The penalisation term in the ICL is aligned with assumptions that make metastable Markov processes amenable to coarse-graining with a HMM. The purpose of coarse-graining is to provide an interpretable model of dynamics which means balancing simplicity and accuracy. Part of the simplicity of a coarse-grained model is being able to interpret given structures (microstates) as belonging, unambiguously, to a particular metastable state. Considering the integrated classification likelihood naturally penalises less interpretable solutions by considering the models' evidence for both the observed states and the classification into hidden states. 


% However, the ICL did not perform perfectly and testing this criteria on a single test case does not prove its general usefulness. Further work is needed to justify its routine use. First further benchmark systems are needed to test whether it identifies  metastable states in well-known systems, e.g., alanine dipeptide. Second, the failure of the BIC in this case is unexpected and it should be possible to calibrate both the ICL and the BIC against the `exact' values of integrated observed, and classification likelihood, using MCMC. This would help to establish whether the source of the failure of both criteria was the assumptions behind their derivation or from the task of coarse-graining approximations of metastable Markov processes. 




% The classification likelihood is also known as the complete-data likelihood because the classification procedure adds in a new variable, the identity of the component associated with each observation. The complete-data likelihood takes both the observation \emph{and} the component variable into account.\cite{mclachlan1988mixture} Instead of 

% Instead of using Bayes factors, which utilise the integrated liIt is reasonable then to look to the classification likelihood and 


% consideration of the integrated complete-data likelihood. This is the likelihood of observing both the observed states $\{s_t\}$ \emph{and} the hidden states $\{h_t\}$: $p\left(\{(s_t, h_t)\}|M_{i}\right)$\footnote{The fact that the hidden states are not, in general, known will be addressed later.}. 

% and the difference between the observed and complete-data likelihood reflect the two main applications of mixture models in general: 

% In order to make the values of the CVLL comparable to the other criteria the CVLL was multiplied by: $2$ to account for the parameters being estimated on half of the data (and the log-likelihood scales linearly with the number of observations), and then $-2$ to account for the same factor in the definition of AIC, BIC and ICL. Thus the \emph{minimum} of the CVLL determines the selected model.
