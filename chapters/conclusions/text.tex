\let\textcircled=\pgftextcircled
\chapter{Conclusions}
\label{chap:conclusions}


The contributions of this thesis have been further demonstrate the scope of Markov models and to introduce a number of ideas from the worlds of machine learning and mixture models to improve the Markov model analysis pipeline. 

Chapter \ref{chap:water} demonstrated the use of MMs to explain deviations to the Stoke-Einstein (S-E) equation by suggesting a mechanism for diffusion of water through a sucrose matrix. The natural basis set to answer this question was the relatively simple cartesian coordinates of the water molecule. This did not require variatonal optimisation of the kind described in \cite{schererVariationalSelectionFeatures2019} and meant that a the modelling could be done at scale - 8000 different MSMs were estimated and used to analyse the data. The results showed that \SI{11.8}{\percent} of the time the water was trapped in cavities defined by the sucrose matrix undergoing reversible hopping dynamics with an average barrier height of \num{6.42}$k_{B}T$. 

To develop this work further a number of improvements and extensions can be made. First, the proportion of time spent in local equilibria could be refined by more accurately partitioning each MD trajectory into reversible/non-reversible sections. Instead of a single position-position decorrelation time of the sucrose matrix (which set the \SI{1}{\nano\second} partition), a local estimate can be used by averaging the autocorrelation function of a small range of values $t-\Delta t < t < t+\Delta t$:
\begin{equation}
\mathrm{R}_{X,  X}(t^{\prime})=\mathbb{E}_{t-\Delta t < t < t+\Delta t}\left[X_{t} \bar{X}_{t+t^{\prime}}\right]
\end{equation}
and choosing the longest time slice such that $\mathrm{R}_{X,  X}(t^{\prime}) > 0.8$ (or some other threshold). Second, using this more accurate partition, the irreversible timescales could be estimated using the Koopman models \cite{wuVariationalApproachLearning2019} could be used. With both sets of timescales estimated a more mathematically precise comaparison of the S-E and cavity dynamics model can be made. Third, using more complex basis sets involving water-sucrose bonds-lengths and relative orientations could by used with variational optimisation would help refine both the timescales and the mechanisms of water transport. 

Chapter \ref{chap:msm} demonstrated how to use a common machine learning technique of Bayesian optimisation of model hyperparameters for an MSM of alanine dipeptide. Specifically, a Gaussian processes (GP) regression was used to model the response surface of an MSM with respect to its hyperparameters and Bayesian optimisation used to optimise the number of microstates, $n$ and the continuous features $\chi$, in basis set construction. Over the range of hyperparameters tested the number of microstates was shown to be irrelevant, compared to the peptide features, in determining the VAMP-2 score. Both the $(\phi, \psi)$ dihedral angles \emph{and} the heavy atom positions captured the slow relaxation processes equally well. Bayesian optimisation was then used to optimise the hyperparameters starting from $50$ randomly sampled seed observations.

The main limitation of this study is that the response surface was unrealistically simple and did not provide adequate variation to demonstrate the utility of estimating the hyperparameter relevance and Bayesian optimisation (proven in other studies \cite{bergstraAlgorithmsHyperParameterOptimizationa}\cite{bergstrajamesbergstraRandomSearchHyperParameter2012}. To improve this,  the range of $n$, the number of microstates, should be shifted from $[10, 1000]$ to $[2, 100]$. This would allow meaningful variation in the VAMP-2 score with respect to both $n$ and $\chi$.  Using this new hyperparameter search space, the demonstration of Bayesian optimisation and the test of the number of required seed observations could be improved by: i) increasing the number of BO steps from \num{10} to \num{100} and ii) repeating the optimisation a larger number of times to gain a statistical insight into its efficacy and a more generalizable value of the number of required seed observations. The increase the generalizability of the conclusions about hyperparameter relevance and optimise the type of surrogate model and BO parameters, the workflow of this chapter should be applied to more benchmark systems such as: .... 

Chapter \ref{chap:hmm} draws on ideas from the mixture model community to demonstrate the use of the integrated classification likelihood (ICL) and other information criteria in determining  the number of hidden states in a HMM.  The benefits of these type of model selection metrics are that they are easy to calculate and do not rely on being able to resolve clear gaps in the eigenvalue spectrum. The ICL was able to correctly the number of metastable states in an HMM of the four well Prinz potential for 3 out of \num{5} lag times tested, while selecting only one extra state the remaining \num{2} lag-times.  The main limitation of this work is that the limited nature of the benchmarking. A number of further steps are needed to gain a better estimate of the generalizability of the ICL. First, bootstrap the simulation data and calculate the selected number of hidden states on each bootstrap sample. This would give probabilities of the each criteria selecting the correct number of states, rather than the current single point estimates. Second, and still using the Prinz potential simulation data, calculate performance of each criteria with differing amounts of data. This would allow the performance of each criteria under more realistic conditions of limited data to be assessed. Third, more benchmark systems are needed, both `toy' models e.g. the 2D triple well from \cite{noeProjectedHiddenMarkov2013a} and xxxx and well understood molecular benchmark systems such as alanine dipeptide and xxxx.  To extend this work futher and bring statistical modelling of bimolecular systems ever closer to machine learning best practice, the use of surrogate models which take into account conditional hyperparameter search spaces such as TPEs or RFs could by used. 

Chapter \ref{chap:aadh} used the response surface and BO methods from chapter \ref{chap:msm} and the model selection techniques of chapter \ref{chap:hmm} to the case of AADH. A simulation data set of AADH was created and the response surface using an expanded set of hyperparameters was estimated and optimised. A number of sensitivity cases were suggested from inspection of the optimised response surface and HMMs were estimated using the number of hidden states suggested by the ICL. The most relevant parameters for determining the VAMP-2 score were the TICA lag time and the optimal continuous feature was the backbone and residue dihedral angles. Coarse graining the optimal MSM using a Bayesian HMM with the ICL selected number of hidden states revealed a complex network of states. The slowest relaxation process of approximately \SI{1}{\micro\second} involved transport between two unreactive states through a flux bottleneck state which has the shortest average donor-acceptor distance and was thus deemed the most `reactive'. The second sensitivity test (and the only sensitivity test to converge a HMM) did not confirm these results and showed a qualitatively different story albeit with similar relaxation timescales. 

The main drawback of this work is the AADH data set which must be corrected and expanded before any inferences can be drawn. First, the mistake in the disulphide bond must corrected and the simulation cell re-equilibrated. Second, the sampling trajectories must be initialized from independent starting structures by minimizing and re-equilibrating structures taken from a seeding trajectory. Third, the source of the large conformational changes in the loop structure adjacent to the active site and the tail residues must be investigated to ensure that the sampling is taking place in  conformations relevant for the rate determining reaction. The amount of simulation data should be determined by monitoring the implied timescale plots for optimized MSMs, or through an adaptive sampling method \cite{doerrOntheFlyLearningSampling2014}. 